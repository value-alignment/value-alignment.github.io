<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Artificial Intelligence and the Value Alignment Problem</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            background-color: #f4f4f4;
            color: #333;
        }
        header {
            background-color: #fff;
            text-align: center;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        header img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
        }
        main {
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        h1, h3, h4 {
            text-align: center;
        }
        ul {
            padding-left: 20px;
        }
        .citation {
            background: #f8f8f8;
            padding: 10px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: monospace;
        }
        a {
            color: #0073e6;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

<header>
    <img src="AI-VAP-Cover.png" alt="AI-VAP Cover">
    <h1>Artificial Intelligence and the Value Alignment Problem</h1>
</header>

<main>
    <p><strong>Travis LaCroix</strong><br>
    Forthcoming, Broadview Press. <a href="https://broadviewpress.com/product/artificial-intelligence-and-the-value-alignment-problem/#tab-description">Order here</a>.</p>

    <p>Written for an interdisciplinary audience, this book provides strikingly clear explanations of the many difficult technical and moral concepts central to discussions of ethics and AI. It serves as an introduction to the value alignment problem: ensuring AI systems align with human values. LaCroix redefines the problem as a structural one, linking AI ethics topics like bias, fairness, transparency, and opacity to the core issue of value alignment. Case studies throughout the book highlight the ethical challenges in AI development and implementation.</p>

    <h3>Draft PDF coming soon</h3>
    
    <h3>Table of Contents (Tentative)</h3>
    <ul>
        <li><strong>Introduction</strong></li>
        <li><strong>Part I: Basic Concepts</strong>
            <ul>
                <li>Chapter 1 - A Brief History of Artificial Intelligence</li>
                <li>Chapter 2 - Artificial Intelligence Today</li>
                <li>Chapter 3 - The Value Alignment Problem</li>
            </ul>
        </li>
        <li><strong>Part II: Axes of Value Alignment</strong>
            <ul>
                <li>Chapter 4 - Objectives</li>
                <li>Chapter 5 - Information</li>
                <li>Chapter 6 - Principals</li>
            </ul>
        </li>
        <li><strong>Part III: Approaches to Value Alignment</strong>
            <ul>
                <li>Chapter 7 - AI Safety</li>
                <li>Chapter 8 - Machine Ethics</li>
            </ul>
        </li>
        <li><strong>Part IV: Values and Value Alignment: Philosophical Questions</strong>
            <ul>
                <li>Chapter 9 - Measuring Degrees of Alignment</li>
                <li>Chapter 10 - Normativity and Language</li>
                <li>Chapter 11 - Values and Value-Ladenness</li>
                <li>Chapter 12 - Conclusion</li>
            </ul>
        </li>
        <li><strong>Appendices</strong>
            <ul>
                <li>Superintelligence and the Control Problem</li>
            </ul>
        </li>
    </ul>

    <h4>Citation:</h4>
    <div class="citation">
        <pre>
 @book{LaCroix-2023-Value-Alignment-Book,
     author = "Travis LaCroix",
     title = "Artificial Intelligence and the Value Alignment Problem: A Philosophical Introduction",
     publisher = "Broadview Press",
     year = 2023,
     url = "https://value-alignment.github.io/value-alignment-book/"
 }
        </pre>
    </div>
</main>

</body>
</html>
